hydra:
  job:
    chdir: false

target:
  data:
    train: eacf/targets/data/aldp_train.h5
    val: eacf/targets/data/aldp_val.h5
  aux:
    conditioned_on_x: true
    scale_init: 0.5
    trainable_augmented_scale: false

flow:
  n_aug: 1
  base:
    x_dist:
      type: centre_gravity_gaussian
    aux:
      conditioned_on_x: ${target.aux.conditioned_on_x}
      scale_init: ${target.aux.scale_init}
      trainable_augmented_scale: false
  dim: 3
  nodes: 22
  n_layers: 20
  scaling_layer: true
  scaling_layer_conditioned: true
  identity_init: true
  type: spherical # non_equivariant proj spherical along_vector
  kwargs:
    non_equivariant:
      transform_type: real_nvp # spline or real_nvp
      spline_num_bins: 8
      spline_max_abs_min: 10.
      n_inner_transforms: 1
    along_vector:
      n_inner_transforms: 3
      dist_spline_max: 10.
      spline_num_bins: 8
    spherical:
      n_inner_transforms: 1
      dist_spline_max: 10.
      spline_num_bins: 8
      reflection_invariant: false
    proj:
      transform_type: real_nvp # spline or real_nvp
      n_inner_transforms: 1
      num_bins: 8
      lower: -10.
      upper: 10.
  nets:
    type: egnn # mace or egnn or e3transformer or e3gnn
    embedding_dim: 32
    num_discrete_feat: 22  # Number of atoms.
    egnn:
      name: egnn
      n_blocks: 3 # number of layers
      mlp_units: [ 128, 128 ]
      n_invariant_feat_hidden: 128
      cross_multiplicity_shifts: true
    mlp_head_config:
      mlp_units: [ 64, 64 ]
      stable: true
    non_equivariant_transformer_config:
      output_dim: 128
      key_size_per_node_dim_in: 4  # key_size = multiplicity * dim * key_size_per_node_dim_in
      n_layers: 3
      mlp_units: [64, 64]
      num_heads: 3


training:
  optimizer:
    init_lr: 0.
    optimizer_name: adam
    use_schedule: true
    peak_lr: 1e-4 # can be null
    end_lr: 0. # can be null
    warmup_n_epoch: 1 # can be null
    max_global_norm: 10000.0
    max_param_grad: null
    dynamic_grad_ignore_and_clip: true
  use_64_bit: true
  n_epoch: 50
  batch_size: 20
  plot_batch_size: 1000
  seed: 0
  train_set_size: null
  test_set_size: 100000
  n_checkpoints: 10
  n_eval: 10
  K_marginal_log_lik: 1
  save: true
  save_dir: out/aldp
  resume: true
  runtime_limit: 23.5
  use_flow_aux_loss: true
  aux_loss_weight: 1.0
  last_iter_info_only: true
  debug: false
  factor_to_train_non_eq_flow: 4
  data_augmentation_for_non_eq: true
  per_batch_masking: true
  use_multiple_devices: true
  use_scan: true
  verbose_info: true


eval:
  plot_n_batches: 100


logger:
  pandas_logger:
    save_period: 1 # how often to save the pandas dataframe as a csv

#defaults:
#  - override hydra/launcher: joblib

hydra:
  job:
    chdir: false

target:
  data:
    train: target/data/aldp_500K_train_mini.h5
    val: target/data/aldp_500K_test_mini.h5
  aux:
    conditioned_on_x: true
    scale_init: 1.0
    trainable_augmented_scale: false

flow:
  n_aug: 3
  act_norm: false
  base:
    x_dist:
      type: centre_gravity_gaussian
      a: 0.3
      trainable_mode_scale: false
    aux:
      conditioned_on_x: ${target.aux.conditioned_on_x}
      scale_init: ${target.aux.scale_init}
      trainable_augmented_scale: false
  dim: 3
  nodes: 22
  n_layers: 8
  identity_init: true
  type: along_vector #  nice proj spherical along_vector
  kwargs:
    n_inner_transforms: 3
    along_vector:
      n_inner_transforms: ${flow.kwargs.n_inner_transforms}
      dist_spline_max: 10.
      spline_num_bins: 8
    spherical:
      n_inner_transforms: ${flow.kwargs.n_inner_transforms}
      dist_spline_max: 10.
      spline_num_bins: 8
    proj:
      transform_type: spline # spline or real_nvp
      n_inner_transforms: ${flow.kwargs.n_inner_transforms}
      num_bins: 8
      lower: -10.
      upper: 10.
      orthogonalization_method: gram-schmidt  #  gram-schmidt or loewdin
  nets:
    type: egnn
    egnn:
      name: egnn
      n_blocks: 3 # number of layers
      mlp_units: [ 32, 32 ]
      n_invariant_feat_hidden: 32
      cross_multiplicity_shifts: true
    mlp_head_config:
      mlp_units: [64,64]
      stable: true


training:
  optimizer:
    init_lr: 0.
    optimizer_name: adam
    use_schedule: true
    peak_lr: 1e-4 # can be null
    end_lr: 0. # can be null
    warmup_n_epoch: 10 # can be null
    max_global_norm: null
    max_param_grad: null
    dynamic_grad_ignore_and_clip: true
  use_64_bit: false
  n_epoch: 64
  batch_size: 64
  eval_batch_size: 128
  plot_batch_size: 1000
  seed: 0
  train_set_size: null
  test_set_size: null
  n_checkpoints: 0
  n_eval: 20
  K_marginal_log_lik: 20
  save: true
  save_dir: aldp_results
  resume: true
  runtime_limit: 23.5
  use_flow_aux_loss: true
  aux_loss_weight: 1.0
  last_iter_info_only: true
  debug: false


eval:
  plot_n_batches: 10


logger:
#  list_logger: null
  pandas_logger:
    save_period: 1 # how often to save the pandas dataframe as a csv
#  wandb:
#    name: aldp_${flow.nets.type}_auxloss${training.use_flow_aux_loss}_bs${training.batch_size} # qm9pos_${flow.type}_${flow.nets.type}_batchsize${training.batch_size}_opt${training.optimizer.optimizer_name}_maxnorm${training.optimizer.max_global_norm}_lrs${training.optimizer.init_lr}-${training.optimizer.peak_lr}_layers${flow.n_layers}_augtargetscale${target.aug_scale}
#    project: fab
#    entity: flow-ais-bootstrap
#    tags: [aldp,loll]

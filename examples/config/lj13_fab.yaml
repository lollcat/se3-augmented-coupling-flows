defaults:
  - training/optimizer: default_lr_schedule
  - flow: default
  - target: default
  - fab: default
#  - override hydra/launcher: joblib

hydra:
  job:
    chdir: false

fab:
  n_intermediate_distributions: 8

flow:
  n_aug: 1
  nodes: 13


training:
  use_64_bit: false
  n_epoch: 14000 # approx how many iter we can do in the training time
  batch_size: 128
  eval_batch_size: 128
  plot_batch_size: 128
  seed: 0
  train_set_size: 1000
  test_set_size: 1000
  n_checkpoints: 20
  n_eval: 20
  K_marginal_log_lik: 20
  save: true
  save_dir: ./lj13fab_results/${flow.type}/${training.seed}
  resume: true
  runtime_limit: null
  use_flow_aux_loss: true
  aux_loss_weight: 1.0
  last_iter_info_only: true
  verbose_info: false
  data_augmentation_for_non_eq: false
  factor_to_train_non_eq_flow: 4

logger:
#  list_logger: null
#  pandas_logger:
#    save_period: 1000 # how often to save the pandas dataframe as a csv
  wandb:
    name: lj13_fab_${flow.type}
    project: fab
    entity: flow-ais-bootstrap
    tags: [lj13,fab,post_sub,cblgpu]


#defaults:
#  - override hydra/launcher: joblib

hydra:
  job:
    chdir: false

target:
  aug_global_centering: false
  aug_scale: 1.0
  custom_samples: false
  temperature: 0.1  # 0.1 or 1 are two good options


flow:
  base:
    aug_scale_init: ${target.aug_scale}
    double_centered_gaussian: false
  dim: 2
  nodes: 4
  n_layers: 4
  identity_init: true
  type: proj # vector_scale  vector_scale nice proj   proj_v2 realnvp_non_eq
  kwargs:
    proj:
      global_frame: false
      process_flow_params_jointly: false
      condition_on_x_proj: true
      gram_schmidt: false
      add_small_identity: true
    proj_v2:
      process_flow_params_jointly: true # if True then specify transformer config lower down.
      condition_on_x_proj: true
      gram_schmidt: false
      n_vectors: 4
  act_norm: false
  compile_n_unroll: 1
  nets:
    type: egnn
    egnn:
      mlp_units: [32,32]
      n_layers: 3
      normalize_by_norms: true
      variance_scaling_init: 0.001
      tanh: false
      agg: mean
      phi_x_max: 1.0
      h_linear_softmax: true
      h_embedding_dim: 16
    transformer: # for proj and proj_v2 flows.
      mlp_units: [32,32]
      num_heads: 3
      key_size: 4
      w_init_scale: 0.1
      n_layers: 3
    mlp_head_config:
      mlp_units: [32, 32]


training:
  optimizer:
    init_lr: 1e-5
    optimizer_name: adam
    use_schedule: true
    peak_lr: 1e-2 # can be null
    end_lr: 1e-3 # can be null
    warmup_n_epoch: 2. # can be null
    max_global_norm: 0.5
  use_64_bit: false
  n_epoch: 50
  batch_size: 100
  plot_batch_size: 256
  seed: 0
  reload_aug_per_epoch: true
  train_set_size: 1000
  test_set_size: 1000
  n_plots: 6
  n_checkpoints: 0
  n_eval: 10
  K_marginal_log_lik: 20
  save: true
  save_dir: dw4_results
  use_flow_aux_loss: true
  aux_loss_weight: 1.
  with_train_info: true

logger:
#  list_logger: null
  wandb:
    name: dw4_${flow.type}
    project: fab
    entity: flow-ais-bootstrap
    tags: [dw4]

